# AutoEncoder-using-MNIST-Dataset

The ipynb file contains the solution to the attached Problem Statement.

It contains the implementation of an AutoEncoder using the MNIST Dataset.

**About AutoEncoder:** 

![image](https://user-images.githubusercontent.com/55259635/185758611-5b6fa34a-2826-4a45-b088-63b3fcfcc4ef.png)

Autoencoders are a specific type of feedforward neural networks where the input is the same as the output. They compress the input into a lower-dimensional code and then reconstruct the output from this representation. The code is a compact “summary” or “compression” of the input, also called the latent-space representation.

You can read more about AutoEncoders [here](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798)

**About the MNIST Dataset:**

The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.

![image](https://user-images.githubusercontent.com/55259635/185758685-4f73ea26-fc66-4e0c-8ace-c47fd1abf57d.png)

You can read more about the dataset as well as download the dataset from [this](http://yann.lecun.com/exdb/mnist) link.
